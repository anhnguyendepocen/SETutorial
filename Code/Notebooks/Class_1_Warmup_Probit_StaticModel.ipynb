{
 "metadata": {
  "kernelspec": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "display_name": "IPython (Python 2)",
   "language": "python",
   "name": "python2"
  },
  "language": "Julia",
  "name": "",
  "signature": "sha256:3c56ecb81846417e8c9f47060d1682ce63ad647f4e9268d4cdfc137f6876bac4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Warm-up"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Numerical Integration"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Trapezoidal Integration"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Import packages\n",
      "using Distributions\n",
      "# Set a seed\n",
      "srand(1)\n",
      "\n",
      "# Plot 1000 points of sine(x) for one cycle of the unit circle\n",
      "n = 1000\n",
      "x = linspace(0, 2*pi, n)\n",
      "s = sin(x)\n",
      "\n",
      "# Trapezoidal integration\n",
      "# function\n",
      "function trapezoidalint(f,a,b,n)\n",
      "        h = (b - a)/n\n",
      "        l = f(a) + f(b)\n",
      "        for k = 1:n\n",
      "                x = a + k*h\n",
      "                l += 2*f(x)\n",
      "        end\n",
      "        l *= h/2\n",
      "        return l\n",
      "end\n",
      "\n",
      "# compare trapezoidal with closed form integration\n",
      "# closed form\n",
      "l = -cos(pi) + cos(0)\n",
      "println(l)\n",
      "\n",
      "# approximations\n",
      "for n in [10,50,100,500,10000]\n",
      "        l = trapezoidalint(sin,0,pi,n)\n",
      "        println(l)\n",
      "end\n",
      "\n",
      "# Monte Carlo Integrarion\n",
      "# function\n",
      "function mcint(f,a,b,n)\n",
      "    l = 0\n",
      "    for k = 1:n\n",
      "            x = rand(Uniform(a,b))\n",
      "            l += f(x)\n",
      "    end\n",
      "    return l *= (b-a)/n\n",
      "end\n",
      "\n",
      "# approximations\n",
      "for n in [10,50,100,500,10000]\n",
      "        l = mcint(sin,0,pi,n)\n",
      "        println(l)\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2.0\n",
        "1.9835235375094546\n",
        "1.9993419830762615\n",
        "1.9998355038874436\n",
        "1.999993420259403\n",
        "1.9999999835506606\n",
        "1.919264781105286\n",
        "2.0276218639370494\n",
        "2.0753482141242006\n",
        "1.9383023228517158\n",
        "1.9810130587148964\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Simple Optimization Exercises"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Use relevant packages\n",
      "using Optim\n",
      "using Distributions\n",
      "\n",
      "# Ronsensbrock function\n",
      "function rosenbrock(x)\n",
      "        xf = x[2:end]\n",
      "        xl = x[1:end-1]\n",
      "        return sum((1-x).^2) + sum(100*(xf - xl.^2).^2)\n",
      "end\n",
      "\n",
      "# optimize\n",
      "optimal = optimize(rosenbrock, zeros(10), method = :l_bfgs)\n",
      "rosenbrockmin = optimal.minimum\n",
      "println(rosenbrockmin)\n",
      "\n",
      "# Likelihood (normal mean zero unknown variance = 1)\n",
      "# generate data\n",
      "N = 10000\n",
      "x = rand(Normal(0,1),N)\n",
      "\n",
      "# closed form mle\n",
      "mle = sum(x.^2)/N\n",
      "println(mle)\n",
      "\n",
      "# negative of likelihood\n",
      "function llknorm(theta)        \n",
      "        # transform parameter to avoid evaluating\n",
      "        # outside function domain\n",
      "        theta  = exp(theta)\n",
      "        l = log(theta) + (1./(N*theta))*sum(x.^2)\n",
      "        return l[1]\n",
      "end\n",
      "\n",
      "optimal = optimize(llknorm, [1.7], method = :l_bfgs)\n",
      "mleopt = exp(optimal.minimum)\n",
      "println(mleopt)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0.9999999999610119,0.999999999947598,0.9999999999209166,0.9999999998890492,0.9999999998216139,0.9999999996921615,0.9999999994320989,0.9999999989212546,0.9999999978868321,0.9999999958089348]\n",
        "1.0127966514661348\n",
        "[1.0127966573681844]\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Probit"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Data Simulation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Probit\n",
      "# data generation\n",
      "N = 10000\n",
      "beta = [3,1.5]\n",
      "\n",
      "x1 = [rand(Normal(0,1.5)) for i = 1:N]\n",
      "x2 = [rand(Uniform(0,1)) for i = 1:N]\n",
      "X = [x1 x2]\n",
      "\n",
      "E = [rand(Normal(0,1)) for i = 1:N]\n",
      "\n",
      "Ystar = X*beta + E\n",
      "d = [Ystar[i] > 0 for i = 1:N]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "10000-element Array{Any,1}:\n",
        " false\n",
        " false\n",
        "  true\n",
        "  true\n",
        " false\n",
        " false\n",
        "  true\n",
        "  true\n",
        "  true\n",
        "  true\n",
        "  true\n",
        "  true\n",
        " false\n",
        "     \u22ee\n",
        "  true\n",
        "  true\n",
        "  true\n",
        "  true\n",
        "  true\n",
        " false\n",
        "  true\n",
        "  true\n",
        " false\n",
        " false\n",
        "  true\n",
        "  true"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Optimization"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# negatve of the likelihood\n",
      "function llkprobit(B)\n",
      "        l_0 = logcdf(Normal(0,1), -X*B)\n",
      "        l_1 = logcdf(Normal(0,1),  X*B)\n",
      "        for i = 1:N\n",
      "                if l_0[i] == -Inf\n",
      "                        l_0[i] = log(1e-300)\n",
      "                elseif l_1[i] == -Inf\n",
      "                        l_1[i] = log(1e-300)\n",
      "                end\n",
      "        end\n",
      "        return l = -sum(d.*l_1 + (1-d).*l_0)\n",
      "end\n",
      "\n",
      "optimal = optimize(llkprobit, beta, method = :l_bfgs)\n",
      "mleprobit = optimal.minimum\n",
      "println(mleprobit)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[2.9682016839759107,1.4575276094365133]\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Structural Model: Static"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Data Simulation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Use relevant packages\n",
      "using Optim\n",
      "using Distributions\n",
      "\n",
      "# Parameters\n",
      "# model\n",
      "N = 1000; T = 6; betak = .5; betan = .2; sigmaeps = .4\n",
      "pi = .2; gamma = .8; sigmaeta = 1; covepseta = .3\n",
      "\n",
      "# simulation\n",
      "y_lb = 0; y_ub = 10\n",
      "z_lb = 0; z_ub = 5\n",
      "k_lb = 0; k_ub = 5\n",
      "n_lb = 0; n_ub = 3\n",
      "\n",
      "# Simulate\n",
      "# y\n",
      "y = zeros(N,T)\n",
      "for t = 1:T\n",
      "        y[:,t] = [rand(Uniform(y_lb,y_ub)) for i = 1:N]\n",
      "end\n",
      "\n",
      "# z,kappa,n (static over time)\n",
      "z = zeros(N,T)\n",
      "kappa = zeros(N,T)\n",
      "n = zeros(N,T)\n",
      "\n",
      "z_N = [rand(Uniform(z_lb,z_ub)) for i = 1:N]\n",
      "kappa_N = [rand(Uniform(k_lb,k_ub)) for i = 1:N]\n",
      "n_N = [rand(Uniform(n_lb,n_ub)) for i = 1:N]\n",
      "\n",
      "# z,kappa,n (wide)\n",
      "for t = 1:T\n",
      "        z[:,t] = z_N\n",
      "        kappa[:,t] = kappa_N\n",
      "        n[:,t] = n_N\n",
      "end\n",
      "\n",
      "# unobserved\n",
      "eps = zeros(N,T)\n",
      "eta = zeros(N,T)\n",
      "\n",
      "for t = 1:T\n",
      "        epseta =  [rand(MvNormal([sigmaeps^2 covepseta; covepseta sigmaeta^2])) for i = 1:N]\n",
      "        for i = 1:N\n",
      "                eps[i,t] = epseta[i,1][1]\n",
      "                eta[i,t] = epseta[i,1][2]\n",
      "        end\n",
      "end\n",
      "\n",
      "w = gamma*z + eta\n",
      "U1 = y + gamma*z + eta - pi*n\n",
      "U0 = y + betak*kappa + betan*n + eps\n",
      "v  = U1 - U0\n",
      "\n",
      "d = zeros(N,T)\n",
      "for t = 1:T\n",
      "        for i = 1:N\n",
      "                d[i,t] = v[i,t] > 0\n",
      "        end\n",
      "end\n",
      "\n",
      "# All data in a Matrix\n",
      "womanssample = [y z kappa n d w]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "1000x36 Array{Float64,2}:\n",
        " 5.15942    2.74391  3.11657   9.97064   \u2026   0.234438  -0.88295   -1.55441 \n",
        " 6.36083    6.95109  4.23269   8.3528        5.08709    4.04625    4.93101 \n",
        " 7.61061    2.05991  8.99828   1.14929       2.39923    3.33326    1.76533 \n",
        " 7.86855    6.54197  2.36346   9.0549        2.72541    4.16118    1.84609 \n",
        " 0.738463   9.53959  3.97033   0.537531      3.53525    3.29924    3.53546 \n",
        " 0.22735    0.53144  2.30747   6.13537   \u2026   0.449827   1.20664    3.05686 \n",
        " 8.17484    8.3624   1.53229   6.69208      -0.172194   0.825548   0.891972\n",
        " 4.55776    5.42689  4.30266   9.00718       4.2724     3.62174    4.86936 \n",
        " 7.81224    6.02529  1.70439   6.59092       4.01567    0.953379   3.81368 \n",
        " 9.77668    4.29122  5.80549   8.763         3.81293    4.17537    2.82033 \n",
        " 4.27567    4.25975  0.469574  6.7508    \u2026   1.37957   -0.11711   -1.4402  \n",
        " 7.18078    3.01035  0.709554  3.06978       2.56036    1.26465    0.436204\n",
        " 3.95313    2.16398  2.65786   0.501547      1.36786    2.7918     2.05393 \n",
        " \u22ee                                       \u22f1                         \u22ee       \n",
        " 9.30595    7.0525   6.82345   6.36477       5.1097     2.71557    1.93325 \n",
        " 0.0937005  1.1734   1.82516   5.59521       2.10929    2.42905    2.26203 \n",
        " 3.33869    6.00788  9.86443   7.93942   \u2026   3.19318    0.331755   2.28287 \n",
        " 0.590047   4.42675  5.64477   2.49462       1.21413    1.95037    2.02424 \n",
        " 7.29002    7.0072   4.2637    7.0876        0.388076   0.400341   1.13142 \n",
        " 9.45374    4.88841  4.05855   2.84121       3.89313    5.51509    3.58955 \n",
        " 5.3249     6.79915  2.00272   8.46265       1.89881    4.14818    1.87493 \n",
        " 4.97594    1.37933  2.88941   8.63086   \u2026   3.27087    1.02685    2.26996 \n",
        " 9.49761    4.27894  4.63126   7.00413       0.432256   1.1621     1.29436 \n",
        " 7.68026    2.95888  3.09925   6.05786      -0.570306   3.19075    2.55139 \n",
        " 4.22828    6.00753  4.96167   0.8647        0.668698   1.10289    3.11075 \n",
        " 8.27462    6.25204  6.20204   7.35172       1.55533    2.7009     1.04479 "
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Estimation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Define variables\n",
      "T = 6\n",
      "y = womanssample[:,1:T]\n",
      "z = womanssample[:,T+1:2*T]\n",
      "kappa = womanssample[:,2*T+1:3*T]\n",
      "n = womanssample[:,3*T+1:4*T]\n",
      "d = womanssample[:,4*T+1:5*T]\n",
      "w = womanssample[:,5*T+1:6*T]\n",
      "\n",
      "# Likelihood\n",
      "function llks(theta)\n",
      "        # transform parameter to avoid evaluating\n",
      "        # outside function domain\n",
      "        betak     = theta[1]\n",
      "        sigmaeps  = exp(theta[2])\n",
      "        pibetan   = theta[3]\n",
      "        gamma     = theta[4]\n",
      "        sigmaeta  = exp(theta[5])\n",
      "        covepseta = (1/(1 + exp(-theta[6])) - .5)*2*exp(theta[2])*exp(theta[5])\n",
      "\n",
      "        # define locals\n",
      "        covxieta = sigmaeta^2 - covepseta\n",
      "        sigmaxi  = sqrt(sigmaeta^2 + sigmaeps^2 - 2*covepseta)\n",
      "        xistar   = z*gamma - n*pibetan - kappa*betak\n",
      "\n",
      "        #l_0\n",
      "        l_0 = logcdf(Normal(0,1), -xistar./sigmaxi)\n",
      "\n",
      "        #l_1\n",
      "        pdfl1     = pdf(Normal(0,1), (w - z*gamma)/sigmaeta)\n",
      "        arg1cdfl1 = xistar + (covxieta/(sigmaeta^2))*(w - z*gamma)\n",
      "        arg2cdfl1 = sqrt(sigmaxi^2 - (covxieta^2)/(sigmaeta^2))\n",
      "        cdfl1     = cdf(Normal(0,1), arg1cdfl1/arg2cdfl1)\n",
      "\n",
      "        l_1 = log((1/sigmaeta)*pdfl1.*cdfl1)\n",
      "\n",
      "        return l = -sum(d.*l_1 + (1-d).*l_0)\n",
      "end\n",
      "\n",
      "# Optimization\n",
      "# initial condition\n",
      "theta0 = [.5, log(.4), .4, .8, log(1), -log((2*.4*1)/(.3+.4*1) -1)]\n",
      "\n",
      "# display optimization\n",
      "optimal = optimize(llks, [theta0], method = :nelder_mead)\n",
      "mles = optimal.minimum\n",
      "mles[6] = (1/(1 + exp(-mles[6])) - .5)*2*exp(mles[2])*exp(mles[5])\n",
      "mles[2] = exp(mles[2])\n",
      "mles[5] = exp(mles[5])\n",
      "println(mles)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0.49765825863789354,0.3874300896070991,0.4068052801061633,0.7980974648356737,1.0021392934848403,0.29888068890258496]\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Bootstrap"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Import packages\n",
      "using Distributions\n",
      "using Optim\n",
      "using DataFrames\n",
      "\n",
      "# Define variables: individuals, parameters, periods, bsample size, samples\n",
      "N = 1000; P = 6; T = 6; M=convert(Int,N/2); B = 1000\n",
      "\n",
      "# Optimize for each sample\n",
      "# define likelihood\n",
      "function llks(theta,z,kappa,n,d,w)\n",
      "        # transform parameter to avoid evaluating\n",
      "        # outside function domain\n",
      "        betak     = theta[1]\n",
      "        sigmaeps  = exp(theta[2])\n",
      "        pibetan   = theta[3]\n",
      "        gamma     = theta[4]\n",
      "        sigmaeta  = exp(theta[5])\n",
      "        covepseta = (1/(1 + exp(-theta[6])) - .5)*2*exp(theta[2])*exp(theta[5])\n",
      "\n",
      "        # define locals\n",
      "        covxieta = sigmaeta^2 - covepseta\n",
      "        sigmaxi  = sqrt(sigmaeta^2 + sigmaeps^2 - 2*covepseta)\n",
      "        xistar   = z*gamma - n*pibetan - kappa*betak\n",
      "\n",
      "        #l_0\n",
      "        l_0 = logcdf(Normal(0,1), -xistar./sigmaxi)\n",
      "\n",
      "        #l_1\n",
      "        pdfl1     = pdf(Normal(0,1), (w - z*gamma)/sigmaeta)\n",
      "        arg1cdfl1 = xistar + (covxieta/(sigmaeta^2))*(w - z*gamma)\n",
      "        arg2cdfl1 = sqrt(sigmaxi^2 - (covxieta^2)/(sigmaeta^2))\n",
      "        cdfl1     = cdf(Normal(0,1), arg1cdfl1/arg2cdfl1)\n",
      "\n",
      "        l_1 = log((1/sigmaeta)*pdfl1.*cdfl1)\n",
      "\n",
      "        return l = -sum(d.*l_1 + (1-d).*l_0)\n",
      "end\n",
      "\n",
      "# initial condition\n",
      "theta0 = [.5, log(.4), .4, .8, log(1), -log((2*.4*1)/(.3+.4*1) -1)]\n",
      "\n",
      "# preallocate space\n",
      "bmles = zeros(P,B)\n",
      "\n",
      "# run optimization\n",
      "for b = 1:B\n",
      "\n",
      "        # random index\n",
      "        rindex = randperm(N)[1:M]\n",
      "\n",
      "        # construct bsample\n",
      "        z = womanssample[rindex,T+1:2*T]\n",
      "        kappa = womanssample[rindex,2*T+1:3*T]\n",
      "        n = womanssample[rindex,3*T+1:4*T]\n",
      "        d = womanssample[rindex,4*T+1:5*T]\n",
      "        w = womanssample[rindex,5*T+1:6*T]\n",
      "\n",
      "        # wrapper function\n",
      "        function wllks(theta)\n",
      "                return llks(theta,z,kappa,n,d,w)\n",
      "        end\n",
      "\n",
      "        # optimization\n",
      "        optimal = optimize(wllks, [theta0], method = :nelder_mead)\n",
      "        mles = optimal.minimum\n",
      "        mles[6] = (1/(1 + exp(-mles[6])) - .5)*2*exp(mles[2])*exp(mles[5])\n",
      "        mles[2] = exp(mles[2])\n",
      "        mles[5] = exp(mles[5])\n",
      "\n",
      "        # store h sample optimum\n",
      "        bmles[:,b] = mles\n",
      "end\n",
      "\n",
      "# Obtain standard errors\n",
      "bsemles = zeros(P,1)\n",
      "for p = 1:P\n",
      "        bsemles[p,1] = std(bmles[p,:])\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bsemles"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "6x1 Array{Float64,2}:\n",
        " 0.00639382\n",
        " 0.0146614 \n",
        " 0.0157817 \n",
        " 0.00444739\n",
        " 0.0072931 \n",
        " 0.0156344 "
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Bootstrap function"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Define variables: individuals, parameters, periods, bsample size\n",
      "N = 1000; P = 6; T = 6; M=convert(Int,N/2)\n",
      "\n",
      "# Optimize for each sample\n",
      "# define likelihood\n",
      "function llks(theta,z,kappa,n,d,w)\n",
      "        # transform parameter to avoid evaluating\n",
      "        # outside function domain\n",
      "        betak     = theta[1]\n",
      "        sigmaeps  = exp(theta[2])\n",
      "        pibetan   = theta[3]\n",
      "        gamma     = theta[4]\n",
      "        sigmaeta  = exp(theta[5])\n",
      "        covepseta = (1/(1 + exp(-theta[6])) - .5)*2*exp(theta[2])*exp(theta[5])\n",
      "\n",
      "        # define locals\n",
      "        covxieta = sigmaeta^2 - covepseta\n",
      "        sigmaxi  = sqrt(sigmaeta^2 + sigmaeps^2 - 2*covepseta)\n",
      "        xistar   = z*gamma - n*pibetan - kappa*betak\n",
      "\n",
      "        #l_0\n",
      "        l_0 = logcdf(Normal(0,1), -xistar./sigmaxi)\n",
      "\n",
      "        #l_1\n",
      "        pdfl1     = pdf(Normal(0,1), (w - z*gamma)/sigmaeta)\n",
      "        arg1cdfl1 = xistar + (covxieta/(sigmaeta^2))*(w - z*gamma)\n",
      "        arg2cdfl1 = sqrt(sigmaxi^2 - (covxieta^2)/(sigmaeta^2))\n",
      "        cdfl1     = cdf(Normal(0,1), arg1cdfl1/arg2cdfl1)\n",
      "\n",
      "        l_1 = log((1/sigmaeta)*pdfl1.*cdfl1)\n",
      "\n",
      "        return l = -sum(d.*l_1 + (1-d).*l_0)\n",
      "end\n",
      "\n",
      "# initial condition\n",
      "theta0 = [.5, log(.4), .4, .8, log(1), -log((2*.4*1)/(.3+.4*1) -1)]\n",
      "\n",
      "function bootstrapmles(B)\n",
      "\n",
      "        # preallocate space\n",
      "        bmles = zeros(P,B)\n",
      "\n",
      "        # run optimization\n",
      "        for b = 1:B\n",
      "\n",
      "                # random index\n",
      "                rindex = randperm(N)[1:M]\n",
      "\n",
      "                # construct bsample\n",
      "                z = womanssample[rindex,T+1:2*T]\n",
      "                kappa = womanssample[rindex,2*T+1:3*T]\n",
      "                n = womanssample[rindex,3*T+1:4*T]\n",
      "                d = womanssample[rindex,4*T+1:5*T]\n",
      "                w = womanssample[rindex,5*T+1:6*T]\n",
      "\n",
      "                # wrapper function\n",
      "                function wllks(theta)\n",
      "                        return llks(theta,z,kappa,n,d,w)\n",
      "                end\n",
      "\n",
      "                # optimization\n",
      "                optimal = optimize(wllks, [theta0], method = :nelder_mead)\n",
      "                mles = optimal.minimum\n",
      "                mles[6] = (1/(1 + exp(-mles[6])) - .5)*2*exp(mles[2])*exp(mles[5])\n",
      "                mles[2] = exp(mles[2])\n",
      "                mles[5] = exp(mles[5])\n",
      "\n",
      "                # store h sample optimum\n",
      "                bmles[:,b] = mles\n",
      "        end\n",
      "        return bmles'\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "bootstrapmles (generic function with 1 method)"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bootstrapmles(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "10x6 Array{Float64,2}:\n",
        " 0.500846  0.389601  0.413717  0.802749  0.999083  0.31022 \n",
        " 0.491588  0.378008  0.408174  0.800647  0.993272  0.281773\n",
        " 0.502467  0.373219  0.390356  0.803458  0.994931  0.279943\n",
        " 0.49737   0.371088  0.399572  0.806111  0.99846   0.291854\n",
        " 0.499603  0.403879  0.397624  0.799195  0.998673  0.291212\n",
        " 0.503847  0.358929  0.405664  0.796285  0.993841  0.269206\n",
        " 0.494594  0.388156  0.407611  0.801031  0.980796  0.277085\n",
        " 0.499559  0.388815  0.397551  0.797615  0.990073  0.304216\n",
        " 0.493937  0.38278   0.413787  0.799513  0.98477   0.291595\n",
        " 0.489909  0.374027  0.43067   0.801175  1.00396   0.294859"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Parallel Bootstrap"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Call number of processors\n",
      "procs = 4\n",
      "addprocs(procs)\n",
      "\n",
      "# Define \"to parallelize process\"\n",
      "require(\"womansbootstrapf.jl\")\n",
      "B = 1000\n",
      "b = 250\n",
      "\n",
      "# Store\n",
      "MPsamples = pmap(bootstrapmles,[b,b,b,b])\n",
      "bmles = vcat(MPsamples[1],MPsamples[2],MPsamples[3],MPsamples[4])\n",
      "\n",
      "# Obtain standard errors through sd of B samples\n",
      "bsemles = zeros(P,1)\n",
      "for p = 1:P\n",
      "        bsemles[p,1] = std(bmles[:,p])\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Simulate Multiple Samples"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Import packages\n",
      "using Distributions\n",
      "using Optim\n",
      "using DataFrames\n",
      "\n",
      "# Parameters\n",
      "# model\n",
      "N = 1000; T = 6; betak = .5; betan = .2; sigmaeps = .4\n",
      "pi = .2; gamma = .8; sigmaeta = 1; covepseta = .3\n",
      "\n",
      "# simulation\n",
      "y_lb = 0; y_ub = 10\n",
      "z_lb = 0; z_ub = 5\n",
      "k_lb = 0; k_ub = 5\n",
      "n_lb = 0; n_ub = 3\n",
      "\n",
      "# samples, parameters, variables\n",
      "H = 10 ; P = 6; V = 6\n",
      "\n",
      "# preallocate space\n",
      "womansmsamples = zeros(1,T*V)\n",
      "\n",
      "for h = 1:H\n",
      "        # simulate\n",
      "        # y\n",
      "        y = zeros(N,T)\n",
      "        for t = 1:T\n",
      "                y[:,t] = [rand(Uniform(y_lb,y_ub)) for i = 1:N]\n",
      "        end\n",
      "\n",
      "        # z,kappa,n (static over time)\n",
      "        z = zeros(N,T)\n",
      "        kappa = zeros(N,T)\n",
      "        n = zeros(N,T)\n",
      "\n",
      "        z_N = [rand(Uniform(z_lb,z_ub)) for i = 1:N]\n",
      "        kappa_N = [rand(Uniform(k_lb,k_ub)) for i = 1:N]\n",
      "        n_N = [rand(Uniform(n_lb,n_ub)) for i = 1:N]\n",
      "\n",
      "        # z,kappa,n (wide)\n",
      "        for t = 1:T\n",
      "                z[:,t] = z_N\n",
      "                kappa[:,t] = kappa_N\n",
      "                n[:,t] = n_N\n",
      "        end\n",
      "\n",
      "        # unobserved\n",
      "        eps = zeros(N,T)\n",
      "        eta = zeros(N,T)\n",
      "\n",
      "        for t = 1:T\n",
      "                epseta =  [rand(MvNormal([sigmaeps^2 covepseta; covepseta sigmaeta^2])) for i = 1:N]\n",
      "                for i = 1:N\n",
      "                        eps[i,t] = epseta[i,1][1]\n",
      "                        eta[i,t] = epseta[i,1][2]\n",
      "                end\n",
      "        end\n",
      "\n",
      "        w = gamma*z + eta\n",
      "        U1 = y + gamma*z + eta - pi*n\n",
      "        U0 = y + betak*kappa + betan*n + eps\n",
      "        v  = U1 - U0\n",
      "\n",
      "        d = zeros(N,T)\n",
      "        for t = 1:T\n",
      "                for i = 1:N\n",
      "                        d[i,t] = v[i,t] > 0\n",
      "                end\n",
      "        end\n",
      "\n",
      "        #store sample h\n",
      "        sampleh = [y z kappa n d w]\n",
      "        womansmsamples = [womansmsamples, sampleh]\n",
      "\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Warning: imported binding for pi overwritten in module Main\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Estimate Multiple Samples"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Define variables: individuals, parameters, periods, variables\n",
      "N = 1000; P = 6; T = 6; V = 6\n",
      "\n",
      "# Optimize for each sample\n",
      "# define likelihood\n",
      "function llks(theta,z,kappa,n,d,w)\n",
      "        # transform parameter to avoid evaluating\n",
      "        # outside function domain\n",
      "        betak     = theta[1]\n",
      "        sigmaeps  = exp(theta[2])\n",
      "        pibetan   = theta[3]\n",
      "        gamma     = theta[4]\n",
      "        sigmaeta  = exp(theta[5])\n",
      "        covepseta = (1/(1 + exp(-theta[6])) - .5)*2*exp(theta[2])*exp(theta[5])\n",
      "\n",
      "        # define locals\n",
      "        covxieta = sigmaeta^2 - covepseta\n",
      "        sigmaxi  = sqrt(sigmaeta^2 + sigmaeps^2 - 2*covepseta)\n",
      "        xistar   = z*gamma - n*pibetan - kappa*betak\n",
      "\n",
      "        #l_0\n",
      "        l_0 = logcdf(Normal(0,1), -xistar./sigmaxi)\n",
      "\n",
      "        #l_1\n",
      "        pdfl1     = pdf(Normal(0,1), (w - z*gamma)/sigmaeta)\n",
      "        arg1cdfl1 = xistar + (covxieta/(sigmaeta^2))*(w - z*gamma)\n",
      "        arg2cdfl1 = sqrt(sigmaxi^2 - (covxieta^2)/(sigmaeta^2))\n",
      "        cdfl1     = cdf(Normal(0,1), arg1cdfl1/arg2cdfl1)\n",
      "\n",
      "        l_1 = log((1/sigmaeta)*pdfl1.*cdfl1)\n",
      "\n",
      "        return l = -sum(d.*l_1 + (1-d).*l_0)\n",
      "end\n",
      "\n",
      "# initial condition\n",
      "theta0 = [.5, log(.4), .4, .8, log(1), -log((2*.4*1)/(.3+.4*1) -1)]\n",
      "\n",
      "function mestimationmles(H)\n",
      "\n",
      "        # preallocate space\n",
      "        mlesm = zeros(P,H)\n",
      "\n",
      "        for h = 1:H\n",
      "\n",
      "                #define sample h\n",
      "                hh = h - 1\n",
      "                i  = (hh*N)+1\n",
      "                j  = h*N\n",
      "\n",
      "                y = womansmsamples[i:j,1:T]\n",
      "                z = womansmsamples[i:j,T+1:2*T]\n",
      "                kappa = womansmsamples[i:j,2*T+1:3*T]\n",
      "                n = womansmsamples[i:j,3*T+1:4*T]\n",
      "                d = womansmsamples[i:j,4*T+1:5*T]\n",
      "                w = womansmsamples[i:j,5*T+1:6*T]\n",
      "\n",
      "                # wrapper function\n",
      "                function wllks(theta)\n",
      "                        return llks(theta,z,kappa,n,d,w)\n",
      "                end\n",
      "\n",
      "                # optimization\n",
      "                optimal = optimize(wllks, [theta0], method = :nelder_mead)\n",
      "                mles = optimal.minimum\n",
      "                mles[6] = (1/(1 + exp(-mles[6])) - .5)*2*exp(mles[2])*exp(mles[5])\n",
      "                mles[2] = exp(mles[2])\n",
      "                mles[5] = exp(mles[5])\n",
      "\n",
      "                # store h sample optimum\n",
      "                mlesm[:,h] = mles\n",
      "        end\n",
      "        return mlesm'\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "mestimationmles (generic function with 1 method)"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mestimationmles(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "10x6 Array{Float64,2}:\n",
        " 0.504062  0.42073   0.405609  0.799891  0.999045  0.297057\n",
        " 0.492338  0.423179  0.420781  0.809203  1.00086   0.311307\n",
        " 0.494012  0.388048  0.402872  0.798049  0.992412  0.279812\n",
        " 0.501121  0.378203  0.391225  0.805144  0.99217   0.294783\n",
        " 0.506523  0.424708  0.397102  0.798695  0.984346  0.294376\n",
        " 0.495147  0.403466  0.414431  0.798635  0.973476  0.286301\n",
        " 0.486693  0.388353  0.412756  0.798069  1.01128   0.304318\n",
        " 0.501001  0.423486  0.40917   0.80591   1.001     0.294434\n",
        " 0.506476  0.421599  0.403877  0.807215  1.01373   0.320408\n",
        " 0.499829  0.388887  0.405058  0.808978  0.995626  0.276025"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}